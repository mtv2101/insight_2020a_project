{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from word_match import regex_matcher\n",
    "from document import survey_doc\n",
    "from classify import classify_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/matt_valley/anaconda3/envs/spacy/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "83060\n",
      "123\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "docs = classify_labels()\n",
    "print(len(docs.ul_df))\n",
    "print(len(docs.l_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "83060 123\n",
      "(83060, 1000) (123, 165)\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5ff2daac661e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/classify.py\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \"\"\"\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [83060, 123]"
     ],
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [83060, 123]",
     "output_type": "error"
    }
   ],
   "source": [
    "docs.train_test(docs, model='tfidf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/matt_valley/anaconda3/envs/spacy/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load all data\n",
    "\n",
    "\n",
    "paths = ['~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/AI_survey_data/2017 to mid 2018 comments.csv',\n",
    "         '~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/AI_survey_data/2018 to mid 2019 comments.csv']\n",
    "\n",
    "q1_df = pd.DataFrame()\n",
    "q2_df = pd.DataFrame()\n",
    "for data_path in paths:\n",
    "    data = survey_doc(data_path)\n",
    "    data.clean_unlabelled_data()\n",
    "    data_q1 = data.df[(data.df['QID']=='61') | (data.df['QID']=='Unique / Unusual')]\n",
    "    q1_df.append(data_q1, ignore_index=True)\n",
    "    data_q2 = data.df[(data.df['QID']=='62') | (data.df['QID']=='One Change')]\n",
    "    q2_df.append(data_q2, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Index(['Comment ID', 'Customer ID', 'Survey ID', 'Respondent ID', 'QID',\n",
      "       'Comment', 'JK label', 'JK sentiment', 'Unnamed: 8'],\n",
      "      dtype='object')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# load labelled data\n",
    "data_path = ['~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/AI_survey_data/Labeled data and sentiments 2017-18 data2.csv']\n",
    "labeled_data = survey_doc(data_path[0], header=0)\n",
    "labeled_data.clean_labelled_data()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "     QID                                               text  \\\n110   62  Clearer communication about expectations and s...   \n\n                                              JK label           JK sentiment  \n110   a posted schedule online would be incredibly ...  Support and resources  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QID</th>\n      <th>text</th>\n      <th>JK label</th>\n      <th>JK sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>110</th>\n      <td>62</td>\n      <td>Clearer communication about expectations and s...</td>\n      <td>a posted schedule online would be incredibly ...</td>\n      <td>Support and resources</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "labeled_data.df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "survey_path_1 = '/home/matt_valley/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/AI_survey_data/2017 to mid 2018 comments.csv'\n",
    "survey_path_2 = '/home/matt_valley/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/AI_survey_data/2018 to mid 2019 comments.csv'\n",
    "\n",
    "df = pd.read_csv(survey_path_1, header=1)\n",
    "df2 = pd.read_csv(survey_path_2, header=1)\n",
    "\n",
    "print(len(df))\n",
    "df = df.dropna(how='any')\n",
    "df2 = df2.dropna(how='any')\n",
    "print(len(df))\n",
    "\n",
    "df = df.rename(columns={\"Comment\": \"text\"})\n",
    "df2 = df2.rename(columns={\"Comment\": \"text\"})\n",
    "\n",
    "text_clean = [len(t) for t in df.text.values]\n",
    "\n",
    "\n",
    "# load spacy model\n",
    "\n",
    "model = 'en_core_web_sm' # for testing on laptop\n",
    "#model = 'en_core_web_lg'\n",
    "#model = 'en_vectors_web_lg' # many more words\n",
    "nlp = spacy.load(model)\n",
    "#sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "#nlp.add_pipe(sentencizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "match = regex_matcher()\n",
    "match_df = pd.DataFrame()\n",
    "for t,text in enumerate(df['text']):\n",
    "    doc = nlp(text)\n",
    "    out_df = match.match_topics(t, doc)\n",
    "    match_df = match_df.append(out_df)\n",
    "    \n",
    "match_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "process_time = timeit.default_timer() - start_time\n",
    "print(str(len(df)) + ' submissions, query took ' + str(process_time) + ' seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(match_df))\n",
    "pd.to_pickle(match_df, '~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/match_df.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "match_df = pd.read_pickle('~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/match_df.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### LOAD EMBEDDING MODEL\n",
    "\n",
    "model = 'en_vectors_web_lg'\n",
    "nlp_vec = spacy.load(model)\n",
    "\n",
    "y_vec = []\n",
    "topics = match_df['topic'].unique()\n",
    "for topic in topics:\n",
    "    y_doc = nlp(topic)\n",
    "    y_vec.append(y_doc.vector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_vec = np.array(y_vec)\n",
    "y_vec.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BUILD CONTEXT VECTORS\n",
    "\n",
    "X = []\n",
    "for n,text in enumerate(match_df['context_span'].values):\n",
    "    X.append(nlp(text).vector)\n",
    "X = np.array(X)\n",
    "print(X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dimensionality reduce\n",
    "\n",
    "pca = PCA(n_components=20, whiten=True, random_state=42)\n",
    "pca.fit(X, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "do tfidf\n",
    "'''\n",
    "\n",
    "all_tfidf = []\n",
    "topics = match_df['topic'].unique()\n",
    "for topic in topics:\n",
    "    temp_df = match_df[match_df['topic']==topic]\n",
    "    data = [sent for sent in temp_df.comment_text]\n",
    "    \n",
    "    n_features = 1000\n",
    "    n_components = 12\n",
    "    n_top_words = 8\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                       max_features=n_features,\n",
    "                                       stop_words='english')\n",
    "\n",
    "    t0 = time.time()\n",
    "    tfidf = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "    feature_array = np.array(tfidf_vectorizer.get_feature_names())\n",
    "    tfidf_sorting = np.argsort(tfidf.toarray()).flatten()[::-1]\n",
    "    \n",
    "    n = 10\n",
    "    top_n = feature_array[tfidf_sorting][:n]\n",
    "    print(topic)\n",
    "    print(top_n)\n",
    "        \n",
    "    all_tfidf.append(tfidf)\n",
    "    print(\"done in %0.3fs.\" % (time.time() - t0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "X = np.empty((0,all_tfidf[0].shape[1]), dtype=all_tfidf[0].dtype)\n",
    "y = np.empty((0))\n",
    "for t,topic_vecs in enumerate(all_tfidf):\n",
    "    print(topic_vecs.shape)\n",
    "    print(X.shape)\n",
    "    X = np.append(X,topic_vecs.toarray(), axis=0)\n",
    "    y = np.append(y,np.ones(topic_vecs.shape[0])*t, axis=0)\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logit = LogisticRegression(class_weight='balanced', \n",
    "                           random_state=42, \n",
    "                           multi_class='multinomial',\n",
    "                           verbose=1,\n",
    "                           max_iter=1000)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    logit.fit(X_train, y_train)\n",
    "    y_pred = logit.predict((X_test))\n",
    "    \n",
    "    print('accuracy = ' + str(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('balenced accuracy = ' + str(metrics.balanced_accuracy_score(y_test, y_pred)))\n",
    "    print('macro precision = ' + str(metrics.precision_score(y_logit.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = logit.predict((X_test))\n",
    "print('accuracy = ' + str(metrics.accuracy_score(y_test, y_pred)))\n",
    "print('balenced accuracy = ' + str(metrics.balanced_accuracy_score(y_test, y_pred)))\n",
    "print('macro precision = ' + str(metrics.precision_score(y_test, y_pred,\n",
    "                           average='macro')))\n",
    "print('recall score = ' + str(metrics.recall_score(y_test, y_pred,\n",
    "                           average='macro')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "                               average='macro')))\n",
    "    print('recall score = ' + str(metrics.recall_score(y_test, y_pred,\n",
    "                               average='macro')))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size=0.1)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f056d84",
   "language": "python",
   "display_name": "PyCharm (insight_2020a_project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}