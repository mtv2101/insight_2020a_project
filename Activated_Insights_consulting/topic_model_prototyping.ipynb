{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "#import cupy\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import some text, in this case restuarant reviews\n",
    "\n",
    "yelp_business_datapath = '/home/matt_valley/PycharmProjects/insight_2020a_project/Resto_names/yelp_dataset/review.json'\n",
    "\n",
    "num_entries = 1000\n",
    "users = []\n",
    "with open(yelp_business_datapath) as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        users.append(json.loads(line))\n",
    "        if i+1 >= num_entries:\n",
    "            break\n",
    "df = pd.DataFrame(users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# load spacy model\n",
    "\n",
    "model = 'en_core_web_sm' # for testing on laptop\n",
    "#model = 'en_core_web_lg'\n",
    "#model = 'en_vectors_web_lg' # many more words\n",
    "nlp = spacy.load(model)\n",
    "#sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "#nlp.add_pipe(sentencizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# rudimentary text chunking pipeline\n",
    "\n",
    "all_sentences = []\n",
    "all_sentence_entities = []\n",
    "all_tokens = []\n",
    "for r, review in enumerate(df.text):\n",
    "    doc = nlp(review)\n",
    "    tokens = [token.text for token in doc]\n",
    "    sentences = [sent for sent in doc.sents]\n",
    "    sentence_entities = [ent.text for ent in doc.ents]\n",
    "    all_tokens.append(tokens)\n",
    "    all_sentences.append(sentences)\n",
    "    all_sentence_entities.append(sentence_entities)\n",
    "    \n",
    "df['tokens'] = all_tokens\n",
    "df['sentences'] = all_sentences\n",
    "df['entities'] = all_sentence_entities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "'''\n",
    "# do it another way, from https://gist.github.com/narulkargunjan/5319ed32d092d1fa7b52fec3a774e0e5\n",
    "columns=['text',\n",
    "           'log_probability',\n",
    "           'stop?',\n",
    "           'punctuation?',\n",
    "           'whitespace?',\n",
    "           'number?',\n",
    "           'out of vocab.?']\n",
    "token_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "for r, review in enumerate(df.text):\n",
    "    doc = nlp(review)\n",
    "    token_attributes = [(token.orth_,\n",
    "                         token.prob,\n",
    "                         token.is_stop,\n",
    "                         token.is_punct,\n",
    "                         token.is_space,\n",
    "                         token.like_num,\n",
    "                         token.is_oov)\n",
    "                        for token in doc]\n",
    "    temp_df = pd.DataFrame(token_attributes, columns=columns)\n",
    "    token_df = token_df.append(temp_df)\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "done in 0.173s.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# data must be a list of strings\n",
    "data = [sent for sent in df.text]\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 20\n",
    "n_top_words = 10\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time.time()\n",
    "tf = tf_vectorizer.fit_transform(data)\n",
    "tfidf = tfidf_vectorizer.fit_transform(data)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "iteration: 1 of max_iter: 20\n",
      "iteration: 2 of max_iter: 20\n",
      "iteration: 3 of max_iter: 20\n",
      "iteration: 4 of max_iter: 20\n",
      "iteration: 5 of max_iter: 20\n",
      "iteration: 6 of max_iter: 20\n",
      "iteration: 7 of max_iter: 20\n",
      "iteration: 8 of max_iter: 20\n",
      "iteration: 9 of max_iter: 20\n",
      "iteration: 10 of max_iter: 20\n",
      "iteration: 11 of max_iter: 20\n",
      "iteration: 12 of max_iter: 20\n",
      "iteration: 13 of max_iter: 20\n",
      "iteration: 14 of max_iter: 20\n",
      "iteration: 15 of max_iter: 20\n",
      "iteration: 16 of max_iter: 20\n",
      "iteration: 17 of max_iter: 20\n",
      "iteration: 18 of max_iter: 20\n",
      "iteration: 19 of max_iter: 20\n",
      "iteration: 20 of max_iter: 20\n",
      "['00', '10', '100', '11', '12', '14', '15', '20', '25', '30', '40', '45', '50', '99', 'able', 'absolutely', 'ac', 'actually', 'add', 'added', 'additional', 'admit', 'affordable', 'afternoon', 'ago', 'ahead', 'air', 'airport', 'amazing', 'ambiance', 'answer', 'anymore', 'apparently', 'appetizer', 'appetizers', 'apple', 'appointment', 'appreciated', 'area', 'aren', 'arrive', 'arrived', 'asian', 'ask', 'asked', 'asking', 'ate', 'atmosphere', 'attention', 'attentive', 'attitude', 'authentic', 'available', 'average', 'avoid', 'away', 'awesome', 'awful', 'bacon', 'bad', 'bag', 'bakery', 'bar', 'barely', 'bartender', 'based', 'basic', 'basically', 'bbq', 'beans', 'beautiful', 'beef', 'beer', 'beers', 'believe', 'best', 'better', 'big', 'birthday', 'bit', 'bite', 'black', 'bland', 'boba', 'bonus', 'book', 'bottle', 'bought', 'bowl', 'box', 'boyfriend', 'bread', 'breakfast', 'bring', 'brisket', 'brought', 'brown', 'brunch', 'buffet', 'bunch', 'burger', 'burgers', 'burrito', 'business', 'busy', 'butter', 'buy', 'caesar', 'cafe', 'cake', 'california', 'called', 'came', 'car', 'caramel', 'card', 'care', 'carry', 'case', 'cash', 'casino', 'casual', 'center', 'certainly', 'chairs', 'change', 'changed', 'charge', 'charged', 'cheap', 'cheaper', 'check', 'checked', 'cheese', 'cheesy', 'chef', 'chicken', 'chinese', 'chips', 'chocolate', 'choice', 'choices', 'choose', 'chose', 'city', 'class', 'clean', 'clear', 'clearly', 'close', 'closed', 'club', 'cocktail', 'cocktails', 'coffee', 'cold', 'come', 'comes', 'comfortable', 'coming', 'company', 'complain', 'complaint', 'complaints', 'completely', 'considering', 'contact', 'continue', 'cooked', 'cookie', 'cool', 'corn', 'cost', 'couldn', 'counter', 'country', 'couple', 'course', 'covered', 'crab', 'crap', 'craving', 'crazy', 'cream', 'credit', 'crepe', 'crispy', 'crowded', 'crust', 'cup', 'cupcakes', 'curry', 'customer', 'customers', 'cut', 'cute', 'daily', 'dam', 'dark', 'date', 'daughter', 'day', 'days', 'deal', 'decent', 'decided', 'decor', 'definitely', 'delicious', 'delivery', 'desert', 'dessert', 'desserts', 'did', 'didn', 'die', 'different', 'difficult', 'dining', 'dinner', 'dip', 'dirty', 'disappointed', 'disappointing', 'discount', 'dish', 'dishes', 'doctor', 'does', 'doesn', 'dog', 'dogs', 'doing', 'dollars', 'don', 'door', 'downtown', 'dr', 'dress', 'dressing', 'drink', 'drinks', 'drive', 'driving', 'dry', 'duck', 'earlier', 'early', 'easy', 'eat', 'eating', 'egg', 'eggplant', 'eggs', 'email', 'employee', 'employees', 'enchiladas', 'end', 'ended', 'english', 'enjoy', 'enjoyed', 'enjoying', 'entire', 'entree', 'entrees', 'environment', 'equipment', 'especially', 'et', 'evening', 'exactly', 'excellent', 'excited', 'expect', 'expected', 'expecting', 'expensive', 'experience', 'explained', 'extra', 'extremely', 'fabulous', 'facility', 'fact', 'fair', 'fairly', 'fajitas', 'family', 'fan', 'fantastic', 'far', 'fast', 'favor', 'favorite', 'favorites', 'feel', 'feeling', 'feels', 'felt', 'filled', 'filling', 'finally', 'finding', 'fine', 'finish', 'finished', 'fish', 'fix', 'fixed', 'flavor', 'flavored', 'flavorful', 'flavors', 'floor', 'food', 'foot', 'forgot', 'forward', 'free', 'french', 'fresh', 'friday', 'fried', 'friend', 'friendly', 'friends', 'fries', 'frozen', 'fruit', 'fun', 'future', 'game', 'games', 'garlic', 'gas', 'gave', 'gem', 'gets', 'getting', 'giant', 'girl', 'girls', 'given', 'giving', 'glad', 'glass', 'glasses', 'gluten', 'goes', 'going', 'gone', 'good', 'got', 'gotten', 'grand', 'greasy', 'great', 'green', 'greeted', 'grill', 'grilled', 'grocery', 'group', 'groupon', 'guess', 'guy', 'guys', 'gym', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happy', 'hard', 'hate', 'having', 'head', 'healthy', 'hear', 'heard', 'heat', 'help', 'helped', 'helpful', 'high', 'highly', 'hit', 'hold', 'hole', 'home', 'homemade', 'honest', 'honestly', 'honey', 'hope', 'horrible', 'hostess', 'hot', 'hotel', 'hour', 'hours', 'house', 'hubby', 'huge', 'hungry', 'husband', 'ice', 'iced', 'idea', 'im', 'imagine', 'immediately', 'important', 'impressed', 'including', 'incredible', 'incredibly', 'indian', 'ingredients', 'inside', 'instead', 'insurance', 'interesting', 'interior', 'intimate', 'isn', 'issue', 'issues', 'italian', 'item', 'items', 'job', 'joint', 'juicy', 'just', 'kabob', 'kept', 'key', 'kid', 'kids', 'kind', 'kitchen', 'knew', 'know', 'knowledgeable', 'knows', 'la', 'lacking', 'ladies', 'lady', 'lamb', 'large', 'las', 'late', 'later', 'layout', 'leave', 'leaving', 'left', 'legs', 'lemon', 'let', 'lettuce', 'level', 'life', 'light', 'like', 'liked', 'limited', 'line', 'lines', 'list', 'literally', 'little', 'live', 'living', 'll', 'lobster', 'local', 'located', 'location', 'locations', 'lol', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'loud', 'love', 'loved', 'lovely', 'loves', 'low', 'lunch', 'mac', 'machine', 'machines', 'main', 'make', 'makes', 'making', 'mall', 'man', 'management', 'manager', 'mango', 'margarita', 'margaritas', 'market', 'mary', 'massage', 'matter', 'maybe', 'meal', 'meals', 'mean', 'means', 'meant', 'meat', 'medium', 'meet', 'member', 'mentioned', 'menu', 'met', 'mexican', 'middle', 'miles', 'milk', 'mind', 'mins', 'minute', 'minutes', 'miss', 'mistake', 'mom', 'money', 'month', 'months', 'morning', 'mouth', 'moved', 'multiple', 'mushroom', 'music', 'mustard', 'nail', 'nails', 'napkins', 'near', 'need', 'needed', 'needs', 'negative', 'neighborhood', 'new', 'nice', 'night', 'non', 'noodles', 'normal', 'normally', 'notch', 'note', 'noticed', 'obviously', 'offer', 'offered', 'office', 'oh', 'oil', 'ok', 'okay', 'old', 'olive', 'ones', 'onion', 'online', 'open', 'opened', 'opinion', 'option', 'options', 'order', 'ordered', 'ordering', 'orders', 'original', 'outdoor', 'outside', 'overall', 'overpriced', 'owned', 'owner', 'owners', 'packed', 'pad', 'paid', 'pain', 'parking', 'particular', 'parts', 'party', 'pass', 'past', 'pasta', 'patient', 'patio', 'pay', 'paying', 'people', 'peppers', 'perfect', 'perfectly', 'person', 'personal', 'personally', 'pho', 'phoenix', 'phone', 'piano', 'pick', 'picked', 'picture', 'pictures', 'pie', 'piece', 'pieces', 'pizza', 'place', 'placed', 'places', 'plan', 'plate', 'plates', 'play', 'pleasant', 'pleased', 'plenty', 'plus', 'point', 'pool', 'pork', 'portion', 'portions', 'positive', 'possible', 'post', 'pot', 'potato', 'potatoes', 'power', 'prefer', 'prepared', 'presentation', 'pretty', 'previous', 'price', 'priced', 'prices', 'pricey', 'pricing', 'prime', 'probably', 'problem', 'process', 'professional', 'provide', 'provided', 'pulled', 'purchase', 'purchased', 'quality', 'questions', 'quick', 'quickly', 'quite', 'ranch', 'range', 'rare', 'rate', 'ravioli', 'read', 'ready', 'real', 'really', 'reason', 'reasonable', 'receive', 'received', 'recently', 'recommend', 'recommended', 'red', 'refund', 'regular', 'relaxing', 'remember', 'repair', 'reservation', 'reservations', 'rest', 'restaurant', 'restaurants', 'return', 'returned', 'returning', 'review', 'reviews', 'rib', 'ribs', 'rice', 'rich', 'right', 'rings', 'road', 'roll', 'rolls', 'room', 'rooms', 'rude', 'run', 'running', 'safe', 'said', 'salad', 'salads', 'salmon', 'salon', 'salsa', 'salt', 'salty', 'sandwich', 'sandwiches', 'sashimi', 'sat', 'satisfied', 'saturday', 'sauce', 'sauces', 'sausage', 'save', 'saved', 'saw', 'say', 'saying', 'says', 'scheduled', 'scottsdale', 'screen', 'seafood', 'seasoned', 'seat', 'seated', 'seating', 'second', 'section', 'seeing', 'seen', 'selection', 'self', 'sell', 'sent', 'seriously', 'serve', 'served', 'server', 'servers', 'service', 'serving', 'set', 'share', 'shared', 'ship', 'shop', 'shopping', 'short', 'showed', 'shrimp', 'sides', 'sign', 'signed', 'simple', 'simply', 'single', 'sister', 'sit', 'sitting', 'situation', 'size', 'slice', 'slow', 'small', 'smaller', 'smell', 'smile', 'soda', 'soft', 'sold', 'solid', 'son', 'soon', 'sorry', 'soup', 'space', 'special', 'specials', 'spectacular', 'spend', 'spent', 'spicy', 'split', 'spot', 'staff', 'stand', 'standard', 'standing', 'star', 'stars', 'start', 'started', 'state', 'stay', 'stayed', 'steak', 'steaks', 'stick', 'stomach', 'stop', 'stopped', 'store', 'stores', 'story', 'strange', 'street', 'strip', 'stuck', 'stuff', 'style', 'sugar', 'suggested', 'summer', 'sunday', 'super', 'sure', 'surprise', 'surprised', 'sushi', 'sweet', 'table', 'tables', 'taco', 'tacos', 'taken', 'takes', 'taking', 'talk', 'talked', 'talking', 'taste', 'tasted', 'tasting', 'tasty', 'tea', 'team', 'tell', 'telling', 'tells', 'tender', 'terrible', 'thai', 'thank', 'thanks', 'thing', 'things', 'think', 'thinking', 'thought', 'time', 'times', 'tip', 'toast', 'today', 'told', 'tomato', 'tons', 'took', 'topped', 'toppings', 'toronto', 'total', 'totally', 'touch', 'town', 'traditional', 'travel', 'treat', 'treated', 'tried', 'trip', 'truly', 'trust', 'try', 'trying', 'tuna', 'turkey', 'turned', 'tv', 'twice', 'type', 'typical', 'understand', 'unfortunately', 'unique', 'unless', 'use', 'used', 'using', 'usual', 'usually', 'valley', 'value', 'variety', 've', 'vegan', 'vegas', 'vegetables', 'vegetarian', 'veggies', 'venetian', 'venue', 'vibe', 'view', 'visit', 'visited', 'visiting', 'wait', 'waited', 'waiter', 'waiting', 'waitress', 'walk', 'walked', 'walking', 'wall', 'want', 'wanted', 'warm', 'wasn', 'watch', 'watched', 'watching', 'water', 'way', 'wedding', 'week', 'weekend', 'weeks', 'weird', 'welcoming', 'went', 'weren', 'white', 'wide', 'wife', 'willing', 'window', 'wine', 'wings', 'wish', 'woman', 'won', 'wonderful', 'work', 'worked', 'working', 'world', 'worse', 'worst', 'worth', 'wouldn', 'wow', 'write', 'wrong', 'yeah', 'year', 'years', 'yelp', 'yes', 'yum', 'yummy']\n",
      "['00', '10', '100', '11', '12', '14', '15', '20', '25', '30', '40', '45', '50', '99', 'able', 'absolutely', 'ac', 'actually', 'add', 'added', 'additional', 'admit', 'affordable', 'afternoon', 'ago', 'ahead', 'air', 'airport', 'amazing', 'ambiance', 'answer', 'anymore', 'apparently', 'appetizer', 'appetizers', 'apple', 'appointment', 'appreciated', 'area', 'aren', 'arrive', 'arrived', 'asian', 'ask', 'asked', 'asking', 'ate', 'atmosphere', 'attention', 'attentive', 'attitude', 'authentic', 'available', 'average', 'avoid', 'away', 'awesome', 'awful', 'bacon', 'bad', 'bag', 'bakery', 'bar', 'barely', 'bartender', 'based', 'basic', 'basically', 'bbq', 'beans', 'beautiful', 'beef', 'beer', 'beers', 'believe', 'best', 'better', 'big', 'birthday', 'bit', 'bite', 'black', 'bland', 'boba', 'bonus', 'book', 'bottle', 'bought', 'bowl', 'box', 'boyfriend', 'bread', 'breakfast', 'bring', 'brisket', 'brought', 'brown', 'brunch', 'buffet', 'bunch', 'burger', 'burgers', 'burrito', 'business', 'busy', 'butter', 'buy', 'caesar', 'cafe', 'cake', 'california', 'called', 'came', 'car', 'caramel', 'card', 'care', 'carry', 'case', 'cash', 'casino', 'casual', 'center', 'certainly', 'chairs', 'change', 'changed', 'charge', 'charged', 'cheap', 'cheaper', 'check', 'checked', 'cheese', 'cheesy', 'chef', 'chicken', 'chinese', 'chips', 'chocolate', 'choice', 'choices', 'choose', 'chose', 'city', 'class', 'clean', 'clear', 'clearly', 'close', 'closed', 'club', 'cocktail', 'cocktails', 'coffee', 'cold', 'come', 'comes', 'comfortable', 'coming', 'company', 'complain', 'complaint', 'complaints', 'completely', 'considering', 'contact', 'continue', 'cooked', 'cookie', 'cool', 'corn', 'cost', 'couldn', 'counter', 'country', 'couple', 'course', 'covered', 'crab', 'crap', 'craving', 'crazy', 'cream', 'credit', 'crepe', 'crispy', 'crowded', 'crust', 'cup', 'cupcakes', 'curry', 'customer', 'customers', 'cut', 'cute', 'daily', 'dam', 'dark', 'date', 'daughter', 'day', 'days', 'deal', 'decent', 'decided', 'decor', 'definitely', 'delicious', 'delivery', 'desert', 'dessert', 'desserts', 'did', 'didn', 'die', 'different', 'difficult', 'dining', 'dinner', 'dip', 'dirty', 'disappointed', 'disappointing', 'discount', 'dish', 'dishes', 'doctor', 'does', 'doesn', 'dog', 'dogs', 'doing', 'dollars', 'don', 'door', 'downtown', 'dr', 'dress', 'dressing', 'drink', 'drinks', 'drive', 'driving', 'dry', 'duck', 'earlier', 'early', 'easy', 'eat', 'eating', 'egg', 'eggplant', 'eggs', 'email', 'employee', 'employees', 'enchiladas', 'end', 'ended', 'english', 'enjoy', 'enjoyed', 'enjoying', 'entire', 'entree', 'entrees', 'environment', 'equipment', 'especially', 'et', 'evening', 'exactly', 'excellent', 'excited', 'expect', 'expected', 'expecting', 'expensive', 'experience', 'explained', 'extra', 'extremely', 'fabulous', 'facility', 'fact', 'fair', 'fairly', 'fajitas', 'family', 'fan', 'fantastic', 'far', 'fast', 'favor', 'favorite', 'favorites', 'feel', 'feeling', 'feels', 'felt', 'filled', 'filling', 'finally', 'finding', 'fine', 'finish', 'finished', 'fish', 'fix', 'fixed', 'flavor', 'flavored', 'flavorful', 'flavors', 'floor', 'food', 'foot', 'forgot', 'forward', 'free', 'french', 'fresh', 'friday', 'fried', 'friend', 'friendly', 'friends', 'fries', 'frozen', 'fruit', 'fun', 'future', 'game', 'games', 'garlic', 'gas', 'gave', 'gem', 'gets', 'getting', 'giant', 'girl', 'girls', 'given', 'giving', 'glad', 'glass', 'glasses', 'gluten', 'goes', 'going', 'gone', 'good', 'got', 'gotten', 'grand', 'greasy', 'great', 'green', 'greeted', 'grill', 'grilled', 'grocery', 'group', 'groupon', 'guess', 'guy', 'guys', 'gym', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happy', 'hard', 'hate', 'having', 'head', 'healthy', 'hear', 'heard', 'heat', 'help', 'helped', 'helpful', 'high', 'highly', 'hit', 'hold', 'hole', 'home', 'homemade', 'honest', 'honestly', 'honey', 'hope', 'horrible', 'hostess', 'hot', 'hotel', 'hour', 'hours', 'house', 'hubby', 'huge', 'hungry', 'husband', 'ice', 'iced', 'idea', 'im', 'imagine', 'immediately', 'important', 'impressed', 'including', 'incredible', 'incredibly', 'indian', 'ingredients', 'inside', 'instead', 'insurance', 'interesting', 'interior', 'intimate', 'isn', 'issue', 'issues', 'italian', 'item', 'items', 'job', 'joint', 'juicy', 'just', 'kabob', 'kept', 'key', 'kid', 'kids', 'kind', 'kitchen', 'knew', 'know', 'knowledgeable', 'knows', 'la', 'lacking', 'ladies', 'lady', 'lamb', 'large', 'las', 'late', 'later', 'layout', 'leave', 'leaving', 'left', 'legs', 'lemon', 'let', 'lettuce', 'level', 'life', 'light', 'like', 'liked', 'limited', 'line', 'lines', 'list', 'literally', 'little', 'live', 'living', 'll', 'lobster', 'local', 'located', 'location', 'locations', 'lol', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lost', 'lot', 'lots', 'loud', 'love', 'loved', 'lovely', 'loves', 'low', 'lunch', 'mac', 'machine', 'machines', 'main', 'make', 'makes', 'making', 'mall', 'man', 'management', 'manager', 'mango', 'margarita', 'margaritas', 'market', 'mary', 'massage', 'matter', 'maybe', 'meal', 'meals', 'mean', 'means', 'meant', 'meat', 'medium', 'meet', 'member', 'mentioned', 'menu', 'met', 'mexican', 'middle', 'miles', 'milk', 'mind', 'mins', 'minute', 'minutes', 'miss', 'mistake', 'mom', 'money', 'month', 'months', 'morning', 'mouth', 'moved', 'multiple', 'mushroom', 'music', 'mustard', 'nail', 'nails', 'napkins', 'near', 'need', 'needed', 'needs', 'negative', 'neighborhood', 'new', 'nice', 'night', 'non', 'noodles', 'normal', 'normally', 'notch', 'note', 'noticed', 'obviously', 'offer', 'offered', 'office', 'oh', 'oil', 'ok', 'okay', 'old', 'olive', 'ones', 'onion', 'online', 'open', 'opened', 'opinion', 'option', 'options', 'order', 'ordered', 'ordering', 'orders', 'original', 'outdoor', 'outside', 'overall', 'overpriced', 'owned', 'owner', 'owners', 'packed', 'pad', 'paid', 'pain', 'parking', 'particular', 'parts', 'party', 'pass', 'past', 'pasta', 'patient', 'patio', 'pay', 'paying', 'people', 'peppers', 'perfect', 'perfectly', 'person', 'personal', 'personally', 'pho', 'phoenix', 'phone', 'piano', 'pick', 'picked', 'picture', 'pictures', 'pie', 'piece', 'pieces', 'pizza', 'place', 'placed', 'places', 'plan', 'plate', 'plates', 'play', 'pleasant', 'pleased', 'plenty', 'plus', 'point', 'pool', 'pork', 'portion', 'portions', 'positive', 'possible', 'post', 'pot', 'potato', 'potatoes', 'power', 'prefer', 'prepared', 'presentation', 'pretty', 'previous', 'price', 'priced', 'prices', 'pricey', 'pricing', 'prime', 'probably', 'problem', 'process', 'professional', 'provide', 'provided', 'pulled', 'purchase', 'purchased', 'quality', 'questions', 'quick', 'quickly', 'quite', 'ranch', 'range', 'rare', 'rate', 'ravioli', 'read', 'ready', 'real', 'really', 'reason', 'reasonable', 'receive', 'received', 'recently', 'recommend', 'recommended', 'red', 'refund', 'regular', 'relaxing', 'remember', 'repair', 'reservation', 'reservations', 'rest', 'restaurant', 'restaurants', 'return', 'returned', 'returning', 'review', 'reviews', 'rib', 'ribs', 'rice', 'rich', 'right', 'rings', 'road', 'roll', 'rolls', 'room', 'rooms', 'rude', 'run', 'running', 'safe', 'said', 'salad', 'salads', 'salmon', 'salon', 'salsa', 'salt', 'salty', 'sandwich', 'sandwiches', 'sashimi', 'sat', 'satisfied', 'saturday', 'sauce', 'sauces', 'sausage', 'save', 'saved', 'saw', 'say', 'saying', 'says', 'scheduled', 'scottsdale', 'screen', 'seafood', 'seasoned', 'seat', 'seated', 'seating', 'second', 'section', 'seeing', 'seen', 'selection', 'self', 'sell', 'sent', 'seriously', 'serve', 'served', 'server', 'servers', 'service', 'serving', 'set', 'share', 'shared', 'ship', 'shop', 'shopping', 'short', 'showed', 'shrimp', 'sides', 'sign', 'signed', 'simple', 'simply', 'single', 'sister', 'sit', 'sitting', 'situation', 'size', 'slice', 'slow', 'small', 'smaller', 'smell', 'smile', 'soda', 'soft', 'sold', 'solid', 'son', 'soon', 'sorry', 'soup', 'space', 'special', 'specials', 'spectacular', 'spend', 'spent', 'spicy', 'split', 'spot', 'staff', 'stand', 'standard', 'standing', 'star', 'stars', 'start', 'started', 'state', 'stay', 'stayed', 'steak', 'steaks', 'stick', 'stomach', 'stop', 'stopped', 'store', 'stores', 'story', 'strange', 'street', 'strip', 'stuck', 'stuff', 'style', 'sugar', 'suggested', 'summer', 'sunday', 'super', 'sure', 'surprise', 'surprised', 'sushi', 'sweet', 'table', 'tables', 'taco', 'tacos', 'taken', 'takes', 'taking', 'talk', 'talked', 'talking', 'taste', 'tasted', 'tasting', 'tasty', 'tea', 'team', 'tell', 'telling', 'tells', 'tender', 'terrible', 'thai', 'thank', 'thanks', 'thing', 'things', 'think', 'thinking', 'thought', 'time', 'times', 'tip', 'toast', 'today', 'told', 'tomato', 'tons', 'took', 'topped', 'toppings', 'toronto', 'total', 'totally', 'touch', 'town', 'traditional', 'travel', 'treat', 'treated', 'tried', 'trip', 'truly', 'trust', 'try', 'trying', 'tuna', 'turkey', 'turned', 'tv', 'twice', 'type', 'typical', 'understand', 'unfortunately', 'unique', 'unless', 'use', 'used', 'using', 'usual', 'usually', 'valley', 'value', 'variety', 've', 'vegan', 'vegas', 'vegetables', 'vegetarian', 'veggies', 'venetian', 'venue', 'vibe', 'view', 'visit', 'visited', 'visiting', 'wait', 'waited', 'waiter', 'waiting', 'waitress', 'walk', 'walked', 'walking', 'wall', 'want', 'wanted', 'warm', 'wasn', 'watch', 'watched', 'watching', 'water', 'way', 'wedding', 'week', 'weekend', 'weeks', 'weird', 'welcoming', 'went', 'weren', 'white', 'wide', 'wife', 'willing', 'window', 'wine', 'wings', 'wish', 'woman', 'won', 'wonderful', 'work', 'worked', 'working', 'world', 'worse', 'worst', 'worth', 'wouldn', 'wow', 'write', 'wrong', 'yeah', 'year', 'years', 'yelp', 'yes', 'yum', 'yummy']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#Do LDA\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_components,random_state=0, verbose=1, max_iter=20)\n",
    "lda.fit(tfidf)\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "print(tf_feature_names)\n",
    "print(tfidf_feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Topic #0: facility la clear tried et joint boba cut month rate\n",
      "Topic #1: valley indian healthy tv sauces games entrees craving especially location\n",
      "Topic #2: salon crepe nail nails kabob class english chinese area bonus\n",
      "Topic #3: piano unless multiple near choices pizza soup open lots house\n",
      "Topic #4: venue attitude overpriced ship asian seat basically steak fried wow\n",
      "Topic #5: great miss ask flavored online cheap prepared service needs car\n",
      "Topic #6: sushi crab seafood buffet brunch breakfast crispy rolls pricing awful\n",
      "Topic #7: cake tea ice cream used chocolate bowl apparently cold looks\n",
      "Topic #8: food good place great really chicken like just service delicious\n",
      "Topic #9: team daily stick curry spend range honey soda 14 spectacular\n",
      "Topic #10: email pizza cheesy staff napkins burger awesome layout pricing serve\n",
      "Topic #11: hair massage goes relaxing foot picture filled matter boyfriend particular\n",
      "Topic #12: sugar eggplant love cocktails class bartender fabulous desert morning pie\n",
      "Topic #13: thai trip pad machines sister driving looks play fun walk\n",
      "Topic #14: great service place staff time good love awesome work just\n",
      "Topic #15: pizza breakfast today coffee dr look professional phone office enjoyed\n",
      "Topic #16: hands et lobster pizza grill comfortable wanted kids stuck airport\n",
      "Topic #17: enchiladas affordable et cute area incredible unique online taco thank\n",
      "Topic #18: safe entrees barely country tasting seeing plates forward serve waiter\n",
      "Topic #19: authentic middle pot im hot choice sitting ambiance fajitas frozen\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print_top_words(lda, tfidf_feature_names, n_top_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(2745, 2)\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "                                                  Message  Target\nYelp 0                                 Crust is not good.       0\n     1          Not tasty and the texture was just nasty.       0\n     2  Stopped by during the late May bank holiday of...       1\n     3  The selection on the menu was great and so wer...       1\n     4     Now I am getting angry and I want my damn pho.       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Message</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">Yelp</th>\n      <th>0</th>\n      <td>Crust is not good.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Not tasty and the texture was just nasty.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Stopped by during the late May bank holiday of...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The selection on the menu was great and so wer...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Now I am getting angry and I want my damn pho.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 47
    }
   ],
   "source": [
    "# SENTIMENT ANALYSIS\n",
    "\n",
    "# see: From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015 \n",
    "# http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "\n",
    "\n",
    "\n",
    "# Load our dataset\n",
    "df_yelp = pd.read_table('~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/sentiment_labelled_sentences/yelp_labelled.txt')\n",
    "df_imdb = pd.read_table('~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/sentiment_labelled_sentences/imdb_labelled.txt')\n",
    "df_amz = pd.read_table('~/PycharmProjects/insight_2020a_project/Activated_Insights_consulting/sentiment_labelled_sentences/amazon_cells_labelled.txt')\n",
    "\n",
    "frames = [df_yelp,df_imdb,df_amz]\n",
    "\n",
    "for colname in frames:\n",
    "    colname.columns = [\"Message\",\"Target\"]\n",
    "    \n",
    "# Assign a Key to Make it Easier\n",
    "keys = ['Yelp','IMDB','Amazon']\n",
    "sentiment_df = pd.concat(frames,keys=keys)\n",
    "\n",
    "print(sentiment_df.shape)\n",
    "sentiment_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "sentiment_model = spacy.load(model)\n",
    "stopwords = list(STOP_WORDS)\n",
    "punctuations = string.punctuation\n",
    "parser = English()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# from https://github.com/Jcharis/Natural-Language-Processing-Tutorials/blob/master/Text%20Classification%20With%20Machine%20Learning,SpaCy,Sklearn(Sentiment%20Analysis)/Text%20Classification%20&%20Sentiment%20Analysis%20with%20SpaCy,Sklearn.ipynb\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens]\n",
    "    mytokens = [word for word in mytokens if word not in stopwords and word not in punctuations]\n",
    "    return mytokens\n",
    "\n",
    "tokens = [spacy_tokenizer(s[0].text) for s in df.sentences]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "#Custom transformer using spaCy \n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1)) \n",
    "classifier = LinearSVC()\n",
    "\n",
    "\n",
    "# Features and Labels\n",
    "X = sentiment_df['Message']\n",
    "ylabels = sentiment_df['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('cleaner', <__main__.predictors object at 0x7f83af95d790>),\n                ('vectorizer',\n                 CountVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n                                 input='content', lowercase=True, max_df=1.0,\n                                 max_features=None, min_df=1,\n                                 ngram_range=(1, 1), preprocessor=None,\n                                 stop_words=None, strip_accents=None,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function spacy_tokenizer at 0x7f83a5b603b0>,\n                                 vocabulary=None)),\n                ('classifier',\n                 LinearSVC(C=1.0, class_weight=None, dual=True,\n                           fit_intercept=True, intercept_scaling=1,\n                           loss='squared_hinge', max_iter=1000,\n                           multi_class='ovr', penalty='l2', random_state=None,\n                           tol=0.0001, verbose=0))],\n         verbose=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 62
    }
   ],
   "source": [
    "# Fit our data\n",
    "pipe.fit(X_train,y_train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Predicting with a test dataset\n",
    "sample_prediction = pipe.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Test accuracy:  0.8069216757741348\n",
      "Train accuracy:  0.9895264116575592\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Accuracy\n",
    "print(\"Test accuracy: \",pipe.score(X_test,y_test))\n",
    "print(\"Train accuracy: \",pipe.score(X_train,y_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# VECTORIZE SENTENCES AND SENT FRAGMENTS\n",
    "\n",
    "model = 'en_core_web_sm' # for testing on laptop\n",
    "#model = 'en_core_web_lg'\n",
    "#model = 'en_core_web_lg' # many more words\n",
    "nlp = spacy.load(model, disable=[\"parser\"])\n",
    "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(sentencizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['tagger', 'ner', 'sentencizer']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(nlp.pipe_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def split_sentences(doc, pos_filter=['NOUN', 'VERB', 'ADV']):\n",
    "    # take input document and vectorize in context, and clean\n",
    "    # for topic model return nouns and verbs\n",
    "    # for sentiment return  adverbs    \n",
    "    # return list of lists, corresponding to the filtered entities within each sentences\n",
    "    sent_text = []\n",
    "    all_tokens = []\n",
    "    all_token_vectors = []\n",
    "    for span in doc.sents:\n",
    "        span_doc = span.as_doc(copy_user_data=True)\n",
    "        sent_text.append(span_doc.text)\n",
    "        tokens = [t for i,t in enumerate(span_doc) if t.pos_ in pos_filter]\n",
    "        all_tokens.append(tokens)\n",
    "        token_vectors = [t.vector for i,t in enumerate(span_doc) if t.pos_ in pos_filter]\n",
    "        all_token_vectors.append(token_vectors)\n",
    "    return sent_text, all_tokens, all_token_vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(len(df.text))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "sentence_df = pd.DataFrame(columns=['sentences','tokens','token_vectors'])\n",
    "for r, review in enumerate(df.text):\n",
    "    doc = nlp(review)\n",
    "    sentences, tokens, token_vectors = split_sentences(doc) \n",
    "    entry_df = pd.DataFrame()\n",
    "    entry_df['sentences'] = sentences\n",
    "    entry_df['tokens'] = tokens\n",
    "    entry_df['token_vectors'] = token_vectors\n",
    "    sentence_df = pd.concat([sentence_df, entry_df], axis=0)\n",
    "    #sentence_df.join(entry_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "(47232, 96)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 76
    }
   ],
   "source": [
    "mat = np.array(list(itertools.chain.from_iterable(sentence_df.token_vectors)))\n",
    "mat.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7f09d3444610>]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 92
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(mat)\n",
    "plt.plot(pca.explained_variance_ratio_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-61eb2a5f32ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmean_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmean_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   7136\u001b[0m             \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7137\u001b[0m             \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7138\u001b[0;31m             \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7139\u001b[0m         )\n\u001b[1;32m   7140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    330\u001b[0m                     \u001b[0;34m\" only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 )\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ],
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error"
    }
   ],
   "source": [
    "mean_vecs = []\n",
    "for s in token_vectors:\n",
    "    vec = np.empty([96])\n",
    "    for s_vec in s: # in each sentence\n",
    "        vec = np.vstack((vec,s_vec))\n",
    "        mvec = np.mean(vec, axis=0)\n",
    "    mean_vecs.append(mvec)\n",
    "\n",
    "mean_vecs = np.array(mean_vecs)\n",
    "print(mean_vecs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.66351597e-03,  2.61099718e-04,  2.05655426e-01,\n         1.24012484e-11,  9.03863068e+01,  8.61902138e-04,\n         3.65641190e-02,  2.03120408e-06,  5.56265333e+01,\n         2.57112048e-02,  9.42432761e-12,  2.29605029e-05,\n         1.29068009e-08,  3.04721022e+00,  5.30084154e-09,\n         9.12991332e+02,  2.56850596e-10,  5.95673100e-02,\n         3.81052077e-01,  3.57896313e-02,  3.45892943e-07,\n         2.48507373e+03,  3.73675442e-03,  1.02039819e-04,\n         1.07310023e-02,  2.28007460e+00,  3.65018385e+01,\n         3.91556692e+00,  1.49919566e-09,  3.82102793e-03,\n         1.24066725e-01,  8.02262426e-01,  1.66032549e-10,\n         1.06356714e+03,  2.74782243e-04,  4.91377648e-05,\n         2.33812675e+01,  4.93783414e-01,  1.17585969e+00,\n         4.85569534e+01,  7.69502667e-02,  5.80360317e+00,\n         1.02580655e-04,  1.35581704e-05,  5.02689479e-01,\n         1.13041326e-01,  1.35860276e+00,  1.08825333e+02,\n         1.30079948e-04,  7.01908333e-07,  3.23985159e-01,\n         1.38470089e-08,  1.41075659e+03,  2.34763831e-01,\n         8.13589430e-03,  1.74901906e-05,  6.29041067e-08,\n         3.94573027e-04,  1.61819377e-14,  4.26351370e-03,\n         1.34733524e-02,  2.53886474e+03,  1.63697587e-05,\n         5.64791380e+02,  2.70948233e-03,  2.51048126e+02,\n         2.88298664e-01,  9.55406547e-01,  1.78808958e-01,\n         2.78447330e-01,  1.31378678e-04,  2.31786258e-02,\n         1.96463661e-03,  1.23088703e+01,  6.34954176e-06,\n         5.55607789e+02,  4.79032174e-02,  1.47202145e-02,\n         1.06413107e-04,  1.09827539e-04,  4.35469855e-16,\n         4.94299029e+00,  3.56874037e+00,  1.33711728e-03,\n         1.81414917e+03,  1.51133019e-04,  1.21645052e-02,\n         7.76691455e-03,  3.15685116e-04,  9.49469279e-04,\n         1.51926070e-01,  7.21240502e-05,  1.19838249e-02,\n         4.41828191e-01,  5.45124171e-01,  7.96181266e-04],\n       [ 2.17468429e+00,  8.97732496e-01, -2.53137207e+00,\n         6.91841483e-01, -1.60441089e+00,  1.58065534e+00,\n         2.04891872e+00,  8.36282372e-02,  3.34668541e+00,\n         3.35307145e+00, -1.02411008e+00, -7.97823429e-01,\n         1.76381826e-01, -1.27125645e+00,  2.92869663e+00,\n         3.77029240e-01,  3.16750228e-01, -3.18458223e+00,\n        -6.01830304e-01,  1.20568955e+00, -5.08798420e-01,\n         8.04317892e-02, -3.25060964e-01,  4.84523088e-01,\n        -9.55773234e-01, -1.98942512e-01, -2.18569613e+00,\n        -2.13090110e+00,  1.05743980e+00, -1.78483337e-01,\n         1.11440730e+00,  4.39159298e+00,  5.56242585e-01,\n        -1.17993474e-01,  6.02756786e+00, -1.36326921e+00,\n         2.63030744e+00, -1.69052601e+00, -1.50275540e+00,\n        -1.26815844e+00,  4.54711914e+00,  2.95336872e-01,\n        -8.86835456e-01, -5.10670710e+00, -3.52634907e+00,\n        -9.32076097e-01, -6.88418567e-01, -6.04488730e-01,\n        -2.97763562e+00,  1.04669595e+00, -1.81126392e+00,\n        -2.03500915e+00,  3.91521424e-01,  3.03517056e+00,\n        -3.22378349e+00,  2.23944569e+00,  3.27868795e+00,\n        -1.50152326e-01, -1.99812078e+00,  9.34772849e-01,\n         6.52840078e-01, -1.49813342e+00,  2.45925212e+00,\n        -1.82556558e+00,  1.50125980e+00, -1.12704754e-01,\n        -8.11926842e-01, -4.51931953e+00, -1.51729393e+00,\n        -6.95344210e-01, -2.24094033e-01, -5.38134098e-01,\n        -2.06815362e+00,  2.86533213e+00, -1.09673166e+00,\n        -1.74689162e+00,  3.09637260e+00,  1.89698243e+00,\n         1.28934348e+00, -3.12935114e+00,  4.81162012e-01,\n        -1.40390050e+00, -2.16654897e+00, -2.36272502e+00,\n         2.56188512e-02,  6.05042577e-01, -3.62947083e+00,\n        -4.61784244e-01,  5.82598567e-01,  1.75067234e+00,\n        -1.00962639e+00, -1.47608256e+00,  2.13294148e-01,\n         1.91982532e+00,  4.97838736e+00,  3.42509890e+00],\n       [ 8.64181519e-01,  6.29100919e-01, -1.01712823e+00,\n        -3.27250242e-01,  2.15443802e+00, -1.66199255e+00,\n         1.88811600e+00, -2.00914279e-01, -6.76473022e-01,\n         4.68884563e+00, -8.74842942e-01, -1.60976374e+00,\n         1.28493059e+00, -1.00517428e+00, -9.25065637e-01,\n        -4.73319888e-01, -1.08910918e+00, -2.35239923e-01,\n         3.35069895e-01,  7.26010680e-01,  3.86519933e+00,\n         3.56980562e-02,  4.13858533e-01, -9.43216205e-01,\n        -1.57227242e+00,  1.09057355e+00, -5.72216749e-01,\n        -5.11983967e+00,  4.80004883e+00,  4.71025258e-01,\n        -5.40989399e-01,  4.05155373e+00,  3.57748652e+00,\n        -8.99203420e-01,  9.68671560e-01, -3.74032831e+00,\n         3.28688622e-02, -1.64414930e+00, -3.56062865e+00,\n        -1.86385155e+00,  7.69861412e+00, -1.55380893e+00,\n        -1.93753457e+00, -1.63922358e+00,  6.75435305e-01,\n         6.29765868e-01,  4.23184156e-01, -1.18542898e+00,\n         1.06077409e+00, -8.75368357e-01,  2.29372442e-01,\n        -2.63465214e+00, -1.82557225e+00,  4.27015424e-01,\n        -3.29492640e+00,  4.04258537e+00,  2.73707294e+00,\n         1.31661284e+00, -1.68594646e+00,  1.11052334e+00,\n         2.67967224e+00, -6.08967006e-01, -9.06876922e-01,\n         6.12463355e-01,  6.06884480e-01,  2.33616829e-02,\n         7.17847824e-01, -2.30893683e+00, -3.51358795e+00,\n         2.19609237e+00, -6.67729557e-01, -8.35575461e-01,\n        -6.81106567e-01,  4.88581467e+00, -2.14131069e+00,\n         6.39880061e-01,  3.47759318e+00, -1.06963205e+00,\n         9.15114582e-01, -9.99270618e-01,  9.33483601e-01,\n        -7.05815375e-01, -3.60107970e+00,  8.09032023e-01,\n         3.47040445e-01, -1.52692604e+00, -7.25690126e-01,\n         5.73854983e-01, -1.77669668e+00, -1.06674111e+00,\n        -1.67132998e+00, -1.72091401e+00,  4.01527107e-01,\n         1.76128101e+00,  2.11534047e+00, -7.89411187e-01]])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 32
    }
   ],
   "source": [
    "vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f056d84",
   "language": "python",
   "display_name": "PyCharm (insight_2020a_project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}