{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "#import cupy\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# import some text, in this case restuarant reviews\n",
    "\n",
    "yelp_business_datapath = '/home/matt_valley/PycharmProjects/insight_2020a_project/Resto_names/yelp_dataset/review.json'\n",
    "\n",
    "num_entries = 100\n",
    "users = []\n",
    "with open(yelp_business_datapath) as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        users.append(json.loads(line))\n",
    "        if i+1 >= num_entries:\n",
    "            break\n",
    "df = pd.DataFrame(users)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# load spacy model\n",
    "\n",
    "model = 'en_core_web_sm' # for testing on laptop\n",
    "#model = 'en_core_web_lg'\n",
    "#model = 'en_vectors_web_lg' # many more words\n",
    "nlp = spacy.load(model)\n",
    "#sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "#nlp.add_pipe(sentencizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# rudimentary text chunking pipeline\n",
    "\n",
    "all_sentences = []\n",
    "all_sentence_entities = []\n",
    "all_tokens = []\n",
    "for r, review in enumerate(df.text):\n",
    "    doc = nlp(review)\n",
    "    tokens = [token.text for token in doc]\n",
    "    sentences = [sent for sent in doc.sents]\n",
    "    sentence_entities = [ent.text for ent in doc.ents]\n",
    "    all_tokens.append(tokens)\n",
    "    all_sentences.append(sentences)\n",
    "    all_sentence_entities.append(sentence_entities)\n",
    "    \n",
    "df['tokens'] = all_tokens\n",
    "df['sentences'] = all_sentences\n",
    "df['entities'] = all_sentence_entities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# do it another way, from https://gist.github.com/narulkargunjan/5319ed32d092d1fa7b52fec3a774e0e5\n",
    "columns=['text',\n",
    "           'log_probability',\n",
    "           'stop?',\n",
    "           'punctuation?',\n",
    "           'whitespace?',\n",
    "           'number?',\n",
    "           'out of vocab.?']\n",
    "token_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "for r, review in enumerate(df.text):\n",
    "    doc = nlp(review)\n",
    "    token_attributes = [(token.orth_,\n",
    "                         token.prob,\n",
    "                         token.is_stop,\n",
    "                         token.is_punct,\n",
    "                         token.is_space,\n",
    "                         token.like_num,\n",
    "                         token.is_oov)\n",
    "                        for token in doc]\n",
    "    temp_df = pd.DataFrame(token_attributes, columns=columns)\n",
    "    token_df = token_df.append(temp_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "for r, review in enumerate(df.text[:2]):\n",
    "    doc = nlp(review)\n",
    "    for s,sent in enumerate(doc.sents):\n",
    "        #print(sent.text)\n",
    "        fragment = nlp(sent.text)\n",
    "        for ent in fragment.ents:\n",
    "            print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "        #print(entities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-38cc564d6090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvector_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'en_vectors_web_lg'\u001b[0m \u001b[0;31m# many more words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# installed as package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# path to model data directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_package\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;34m\"\"\"Load a model from an installed package.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/en_vectors_web_lg/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, **overrides)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE052\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath2str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, **overrides)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, exclude, disable)\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0;31m# Convert to list here in case exclude is (default) tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeserializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0mdeserializers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"meta.json\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrsly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         deserializers[\"vocab\"] = lambda p: self.vocab.from_disk(\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         ) and _fix_pretrained_vectors_name(self)\n\u001b[1;32m    927\u001b[0m         deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(\n",
      "\u001b[0;32mvocab.pyx\u001b[0m in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mvectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;31m# Split to support file names like meta.json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mvectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.from_disk.load_vectors\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spacy/lib/python3.7/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (321291300,) and data type float32"
     ],
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (321291300,) and data type float32",
     "output_type": "error"
    }
   ],
   "source": [
    "#vector_model = 'en_vectors_web_lg' # many more words\n",
    "#nlp_vec = spacy.load(vector_model)        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "vectors = []\n",
    "for s, sent in enumerate(df.sentences):\n",
    "    doc = nlp(sent[0].text)\n",
    "    vectors.append(doc.vector)\n",
    "df['sentence_vector'] = vectors\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "                review_id                 user_id             business_id  \\\n0  Q1sbwvVQXV2734tPgoKj4Q  hG7b0MtEbXx5QzbzE6C_VA  ujmEBvifdJM6h6RLv4wQIg   \n1  GJXCdrto3ASJOqKeVWPi6Q  yXQM5uF2jS6es16SJzNHfg  NZnhc2sEQy3RmzKTZnqtwQ   \n2  2TzJjDVDEuAW6MR5Vuc1ug  n6-Gk65cPZL6Uz8qRm3NYw  WTqjgwHlXbSFevF32_DJVw   \n\n   stars  useful  funny  cool  \\\n0    1.0       6      1     0   \n1    5.0       0      0     0   \n2    5.0       3      0     0   \n\n                                                text                 date  \\\n0  Total bill for this horrible service? Over $8G...  2013-05-07 04:34:36   \n1  I *adore* Travis at the Hard Rock's new Kelly ...  2017-01-14 21:30:33   \n2  I have to say that this office really has it t...  2016-11-09 20:09:03   \n\n                                            entities  \\\n0                  [69, 3, 19 cents, Avoid Hospital]   \n1  [the Hard Rock's, Kelly Cardenas Salon, Travis...   \n2      [J. Phillipp, Jewel, Bailey, 80, a year, 25%]   \n\n                                           sentences  \\\n0  [(Total, bill, for, this, horrible, service, ?...   \n1  [(I), (*, adore), (*, Travis, at, the, Hard, R...   \n2  [(I, have, to, say, that, this, office, really...   \n\n                                              tokens  \\\n0  [Total, bill, for, this, horrible, service, ?,...   \n1  [I, *, adore, *, Travis, at, the, Hard, Rock, ...   \n2  [I, have, to, say, that, this, office, really,...   \n\n                                     sentence_vector  \n0  [0.9207042, -0.35722563, 0.5429547, 0.63424003...  \n1  [0.9344967, 3.0664394, 2.522025, -1.4153994, 2...  \n2  [0.14864156, 1.6161582, 0.43045694, -2.1842675...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>user_id</th>\n      <th>business_id</th>\n      <th>stars</th>\n      <th>useful</th>\n      <th>funny</th>\n      <th>cool</th>\n      <th>text</th>\n      <th>date</th>\n      <th>entities</th>\n      <th>sentences</th>\n      <th>tokens</th>\n      <th>sentence_vector</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Total bill for this horrible service? Over $8G...</td>\n      <td>2013-05-07 04:34:36</td>\n      <td>[69, 3, 19 cents, Avoid Hospital]</td>\n      <td>[(Total, bill, for, this, horrible, service, ?...</td>\n      <td>[Total, bill, for, this, horrible, service, ?,...</td>\n      <td>[0.9207042, -0.35722563, 0.5429547, 0.63424003...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n      <td>yXQM5uF2jS6es16SJzNHfg</td>\n      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n      <td>2017-01-14 21:30:33</td>\n      <td>[the Hard Rock's, Kelly Cardenas Salon, Travis...</td>\n      <td>[(I), (*, adore), (*, Travis, at, the, Hard, R...</td>\n      <td>[I, *, adore, *, Travis, at, the, Hard, Rock, ...</td>\n      <td>[0.9344967, 3.0664394, 2.522025, -1.4153994, 2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n      <td>WTqjgwHlXbSFevF32_DJVw</td>\n      <td>5.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>I have to say that this office really has it t...</td>\n      <td>2016-11-09 20:09:03</td>\n      <td>[J. Phillipp, Jewel, Bailey, 80, a year, 25%]</td>\n      <td>[(I, have, to, say, that, this, office, really...</td>\n      <td>[I, have, to, say, that, this, office, really,...</td>\n      <td>[0.14864156, 1.6161582, 0.43045694, -2.1842675...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 64
    }
   ],
   "source": [
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "done in 0.035s.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "\n",
    "# data must be a list of strings\n",
    "data = [sent for sent in df.text]\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time.time()\n",
    "tf = tf_vectorizer.fit_transform(data)\n",
    "tfidf = tfidf_vectorizer.fit_transform(data)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(100, 96)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sent_vec_mat = [vec for vec in df.sentence_vector.values]\n",
    "sent_vec_mat = np.array(sent_vec_mat)\n",
    "print(sent_vec_mat.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n",
      "['10', '100', '14', '15', '17', '20', '25', '30', '45', '50', '80', 'able', 'absolutely', 'accommodating', 'actually', 'add', 'added', 'admit', 'afraid', 'afternoon', 'ago', 'ahead', 'alcohol', 'allow', 'alright', 'amazing', 'ambiance', 'anna', 'appetite', 'appetizer', 'appetizers', 'appreciate', 'area', 'ask', 'asked', 'asking', 'ate', 'atmosphere', 'attention', 'authentic', 'available', 'avoid', 'away', 'awesome', 'awful', 'bachelorette', 'bacon', 'bad', 'balance', 'balcony', 'ball', 'balls', 'bar', 'barely', 'bartender', 'base', 'basically', 'bbq', 'beef', 'beer', 'beers', 'believe', 'bella', 'belly', 'best', 'bet', 'better', 'beware', 'big', 'biggest', 'birthday', 'bit', 'bite', 'bits', 'black', 'bland', 'block', 'blond', 'blown', 'bother', 'bourbon', 'bowl', 'bread', 'breakfast', 'bring', 'brisket', 'broken', 'brought', 'buffet', 'bunch', 'burger', 'business', 'busy', 'butter', 'buy', 'caesar', 'calamari', 'called', 'came', 'car', 'card', 'care', 'carefully', 'case', 'cash', 'casino', 'center', 'chairs', 'changed', 'charge', 'chatting', 'check', 'checked', 'checking', 'cheese', 'chef', 'chewy', 'chicken', 'chinese', 'chips', 'chocolate', 'choice', 'choices', 'choose', 'class', 'clean', 'clearly', 'cleveland', 'close', 'closed', 'club', 'cocktails', 'cold', 'come', 'comes', 'comfort', 'comfortable', 'coming', 'company', 'complaint', 'complaints', 'completed', 'completely', 'conversation', 'cooked', 'cookie', 'corn', 'cost', 'couldn', 'counter', 'country', 'couple', 'crab', 'crap', 'craving', 'cream', 'credit', 'crispy', 'current', 'customer', 'customers', 'cut', 'date', 'daughter', 'dawn', 'day', 'days', 'deal', 'deals', 'decent', 'decided', 'decor', 'definitely', 'delicious', 'delightful', 'department', 'dessert', 'desserts', 'did', 'didn', 'die', 'different', 'dining', 'dinner', 'dip', 'dirty', 'disappointed', 'disappoints', 'dish', 'dishes', 'diverse', 'does', 'doesn', 'doing', 'don', 'door', 'downstairs', 'downtown', 'dozen', 'dr', 'dressing', 'drink', 'drinks', 'drive', 'duck', 'earlier', 'early', 'earth', 'easily', 'easy', 'eat', 'eating', 'employee', 'employees', 'end', 'ended', 'enjoy', 'enjoyed', 'enjoying', 'entire', 'entree', 'entrees', 'especially', 'evening', 'excellent', 'excited', 'expect', 'expectations', 'expected', 'expecting', 'expensive', 'experience', 'explained', 'extra', 'extremely', 'fact', 'fails', 'fairly', 'family', 'fan', 'fantastic', 'far', 'fast', 'fault', 'favor', 'favorite', 'favorites', 'february', 'feel', 'felt', 'filling', 'finally', 'fine', 'finish', 'finished', 'fish', 'fix', 'flat', 'flavor', 'flavors', 'food', 'force', 'free', 'fresh', 'friday', 'fried', 'friend', 'friendly', 'friends', 'fries', 'fry', 'fun', 'funny', 'future', 'game', 'garlic', 'gave', 'gem', 'gentleman', 'gets', 'getting', 'girl', 'girls', 'given', 'giving', 'glad', 'going', 'gone', 'good', 'got', 'granted', 'greasy', 'great', 'green', 'greeted', 'grilled', 'group', 'groups', 'grown', 'guess', 'guy', 'hadn', 'half', 'hand', 'hands', 'happen', 'happened', 'happy', 'hard', 'having', 'head', 'health', 'heard', 'help', 'helped', 'high', 'highly', 'hold', 'hole', 'home', 'horrible', 'hot', 'hotel', 'hour', 'house', 'hubby', 'huge', 'hungry', 'ice', 'idea', 'im', 'impressed', 'incredible', 'ingredients', 'inside', 'instead', 'interesting', 'intimate', 'invited', 'isn', 'issue', 'italian', 'items', 'job', 'joint', 'judge', 'just', 'kabob', 'kept', 'kick', 'kids', 'kind', 'kinds', 'knew', 'know', 'knowledgeable', 'knows', 'lamb', 'lamp', 'large', 'las', 'lasagna', 'lasted', 'late', 'later', 'laugh', 'leave', 'left', 'legs', 'let', 'lettuce', 'level', 'life', 'light', 'like', 'liked', 'limited', 'line', 'lines', 'list', 'literally', 'little', 'live', 'll', 'location', 'lol', 'long', 'look', 'looked', 'looking', 'looks', 'loose', 'lot', 'lots', 'loud', 'love', 'loved', 'loves', 'low', 'lower', 'lunch', 'mac', 'machines', 'main', 'mains', 'make', 'making', 'man', 'manager', 'mango', 'marginally', 'masala', 'material', 'maybe', 'meal', 'mean', 'meat', 'menu', 'mess', 'met', 'mexican', 'min', 'mins', 'minute', 'minutes', 'miss', 'mmmm', 'money', 'month', 'morning', 'mouth', 'music', 'naan', 'names', 'napkins', 'near', 'need', 'needed', 'needs', 'neighborhood', 'new', 'nice', 'night', 'non', 'noodle', 'noodles', 'note', 'noticed', 'number', 'obviously', 'offer', 'oh', 'ok', 'okay', 'old', 'ones', 'online', 'open', 'opened', 'opinion', 'options', 'order', 'ordered', 'ordering', 'orders', 'organized', 'original', 'outside', 'overall', 'overpriced', 'owner', 'owners', 'packed', 'paid', 'pain', 'park', 'particular', 'party', 'pasta', 'patio', 'patrons', 'pay', 'people', 'pepperoni', 'peppers', 'perfect', 'perfectly', 'person', 'personable', 'personally', 'phenomenal', 'phoenix', 'phone', 'pick', 'pictured', 'piece', 'pieces', 'pittsburgh', 'pizza', 'place', 'placed', 'places', 'plan', 'plate', 'play', 'playing', 'pleased', 'plus', 'point', 'polish', 'poor', 'popular', 'pork', 'portion', 'potato', 'potatoes', 'prepare', 'prepared', 'presentation', 'pressure', 'pretty', 'previously', 'price', 'priced', 'prices', 'prime', 'probably', 'problem', 'process', 'professional', 'provide', 'provided', 'pulled', 'purchase', 'quality', 'question', 'quick', 'quite', 'ravioli', 'ready', 'really', 'reason', 'reasonable', 'receive', 'received', 'recommend', 'recommended', 'red', 'register', 'relaxing', 'remember', 'repair', 'repairs', 'request', 'reservation', 'rest', 'restaurant', 'restaurants', 'return', 'review', 'reviews', 'rib', 'rice', 'right', 'rock', 'room', 'rude', 'run', 'said', 'salad', 'salads', 'salon', 'salt', 'salty', 'sandwich', 'sat', 'satisfy', 'saturday', 'sauce', 'sauces', 'sausage', 'saw', 'say', 'saying', 'says', 'scene', 'scottsdale', 'sea', 'seasoned', 'seat', 'seated', 'seating', 'seats', 'second', 'seconds', 'section', 'security', 'seeing', 'seen', 'selection', 'seriously', 'serve', 'served', 'server', 'servers', 'service', 'serving', 'set', 'shop', 'short', 'showed', 'shrimp', 'sides', 'signature', 'simple', 'single', 'sister', 'sit', 'sitting', 'size', 'slow', 'small', 'smokey', 'snack', 'snicker', 'soda', 'soft', 'sold', 'solid', 'son', 'soon', 'soup', 'special', 'spend', 'spicy', 'spot', 'staff', 'stamp', 'stand', 'standard', 'standing', 'star', 'stars', 'start', 'started', 'starting', 'state', 'stayed', 'steak', 'step', 'stomach', 'stop', 'store', 'stores', 'street', 'strip', 'strong', 'stuck', 'stuffed', 'style', 'sunday', 'super', 'support', 'sure', 'surprised', 'sweet', 'table', 'tables', 'tacos', 'taken', 'taking', 'talk', 'talking', 'tapioca', 'taste', 'tasted', 'tasty', 'tea', 'team', 'tell', 'telling', 'tender', 'terrible', 'terrific', 'texas', 'thank', 'thing', 'things', 'think', 'thinking', 'thought', 'time', 'times', 'tip', 'toast', 'today', 'told', 'tomatoes', 'tone', 'took', 'toppings', 'total', 'totally', 'town', 'trained', 'treated', 'tried', 'try', 'trying', 'tuna', 'turn', 'twice', 'unfortunately', 'unique', 'unprofessional', 'unreal', 'upstairs', 'use', 'used', 'usually', 'valley', 've', 'veal', 'vegas', 'vegetables', 'vegetarian', 'veggies', 'version', 'visit', 'vitamin', 'wait', 'waited', 'waiter', 'waiting', 'waitress', 'walk', 'walked', 'walking', 'wall', 'want', 'wanted', 'warm', 'warned', 'wasn', 'watch', 'watched', 'water', 'way', 'week', 'weekend', 'went', 'white', 'wife', 'wine', 'wings', 'wish', 'woman', 'won', 'wonderful', 'wont', 'wonton', 'work', 'working', 'worst', 'worth', 'wouldn', 'wow', 'written', 'wrong', 'year', 'years', 'yelp', 'yes', 'yummy']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#Do LDA\n",
    "k = 5\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=k,random_state=0, verbose=1)\n",
    "lda.fit(tf)\n",
    "\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "print(tf_feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-f056d84",
   "language": "python",
   "display_name": "PyCharm (insight_2020a_project)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}